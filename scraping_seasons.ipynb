{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c19d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cbcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_season_data(season_year):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=5, read=5, backoff_factor=1)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    url = 'https://www.basketball-reference.com/'\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                        'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                        'Chrome/140.0.0.0 Safari/537.36',\n",
    "        'Accept-Language': 'en'\n",
    "    }\n",
    "\n",
    "    # Request for Seasons URL\n",
    "    season_url = urljoin(url, f'/leagues/NBA_{season_year}.html')\n",
    "    season_page = session.get(season_url, headers=headers, timeout=20)\n",
    "    if season_page.status_code != 200:\n",
    "        print(f'Bad status code {season_page.status_code} for {season_url}')\n",
    "        return []\n",
    "    season_soup = BeautifulSoup(season_page.text, 'html.parser')\n",
    "    print(f'NBA_{season_year} URL:', season_page.url)\n",
    "\n",
    "    # Request for Seasons Totals URL\n",
    "    season_total_url = urljoin(url, f'/leagues/NBA_{season_year}_totals.html')\n",
    "    season_total_page = session.get(season_total_url, headers=headers, timeout=20)\n",
    "    if season_total_page.status_code != 200:\n",
    "        print(f'Bad status code {season_total_page.status_code} for {season_total_url}')\n",
    "        return []\n",
    "    season_total_soup = BeautifulSoup(season_total_page.text, 'html.parser')\n",
    "    print(f'NBA_{season_year}_totals URL:', season_total_page.url)\n",
    "\n",
    "    player_links = []\n",
    "    player_ids = []\n",
    "\n",
    "    tds = season_total_soup.find_all('td', {'data-stat': 'name_display'})[:25]\n",
    "\n",
    "    for td in tds:\n",
    "        if td.a:\n",
    "            player_link = urljoin(url, td.a['href'])\n",
    "            player_links.append(player_link)\n",
    "\n",
    "            player_id = td.a['href'].split('/')[2].split('.')[0]\n",
    "            player_ids.append(player_id)\n",
    "\n",
    "            print(f'Player Link: {player_link}, Player ID: {player_id}')\n",
    "\n",
    "    return player_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9a60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_details(player_links):\n",
    "    players = []\n",
    "    positions = []\n",
    "    heights = []\n",
    "    weights = []\n",
    "    experiences = []\n",
    "\n",
    "    for player_link in player_links:\n",
    "        page = requests.get(player_link)\n",
    "        player_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        meta_divs = player_soup.find_all('div', id='meta')\n",
    "\n",
    "        for meta_div in meta_divs:\n",
    "            # Player name\n",
    "            name_tag = meta_div.find('h1')\n",
    "            if name_tag and name_tag.find('span'):\n",
    "                name = name_tag.find('span').text.strip()\n",
    "                players.append(name)\n",
    "\n",
    "            # Position\n",
    "            position_tag = meta_div.find('p', string=lambda text: text and 'Position:' in text)\n",
    "            if position_tag:\n",
    "                position = position_tag.find_all_next('strong')[0].find_next('p').text.strip()\n",
    "                positions.append(position)\n",
    "\n",
    "            # Height and Weight\n",
    "            height_weight_tag = meta_div.find('p', string=lambda text: text and 'cm' in text and 'kg' in text)\n",
    "            if height_weight_tag:\n",
    "                height_weight = height_weight_tag.text.strip()\n",
    "                height_weight_parts = height_weight.split(',')\n",
    "                if len(height_weight_parts) == 2:\n",
    "                    height = height_weight_parts[0].strip()\n",
    "                    weight = height_weight_parts[1].strip()\n",
    "                    heights.append(height)\n",
    "                    weights.append(weight)\n",
    "\n",
    "            # Experience\n",
    "            experience_tag = meta_div.find('p', string=lambda text: text and 'Experience:' in text)\n",
    "            if experience_tag:\n",
    "                experience = experience_tag.find_next('p').text.strip()\n",
    "                experiences.append(experience)\n",
    "\n",
    "    return players, positions, heights, weights, experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca1cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data for the 2019 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2019.html\n",
      "Not found data for the 2019 season\n",
      "\n",
      "Extracting data for the 2020 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2020.html\n",
      "Not found data for the 2020 season\n",
      "\n",
      "Extracting data for the 2021 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2021.html\n",
      "Not found data for the 2021 season\n",
      "\n",
      "Extracting data for the 2022 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2022.html\n",
      "Not found data for the 2022 season\n",
      "\n",
      "Extracting data for the 2023 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2023.html\n",
      "Not found data for the 2023 season\n",
      "\n",
      "Extracting data for the 2024 season\n",
      "Bad status code 403 for https://www.basketball-reference.com/leagues/NBA_2024.html\n",
      "Not found data for the 2024 season\n"
     ]
    }
   ],
   "source": [
    "for season_year in range(2019, 2025):\n",
    "    print(f'\\nExtracting data for the {season_year} season')\n",
    "    player_links = extract_season_data(season_year)\n",
    "    if player_links:\n",
    "        players, positions, heights, weights, experiences = extract_player_details(player_links)\n",
    "        print('Players:', players)\n",
    "        print('Position:', positions)\n",
    "        print('Heights:', heights)\n",
    "        print('Weights:', weights)\n",
    "        print('Experience:', experiences)\n",
    "        print('-'*40)\n",
    "    else:\n",
    "        print(f'Not found data for the {season_year} season')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

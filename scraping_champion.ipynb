{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retry = Retry(connect=5, read=5, backoff_factor=1)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "url = 'https://www.basketball-reference.com/'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                    'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                    'Chrome/140.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'en'\n",
    "}\n",
    "\n",
    "page = session.get(url, headers=headers, timeout=20) \n",
    "\n",
    "if page.status_code != 200:\n",
    "    print(f'Bad status code {page.status_code} for {url}')\n",
    "    \n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print('URL:', page.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoffs_url = urljoin(url, '/playoffs/')\n",
    "\n",
    "playoffs_page = session.get(playoffs_url, headers=headers, timeout=20)\n",
    "\n",
    "if playoffs_page.status_code != 200:\n",
    "    print(f'Bad status code {playoffs_page.status_code} for {playoffs_url}')\n",
    "\n",
    "playoffs_soup = BeautifulSoup(playoffs_page.text, 'html.parser')\n",
    "print(f'Playoffs URL:', playoffs_page.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_links = []\n",
    "\n",
    "ths = playoffs_soup.find_all('th', {'data-stat': 'year_id'})[:3]\n",
    "\n",
    "for td in ths:\n",
    "    if td.a:\n",
    "        player_link = urljoin(url, td.a['href'])\n",
    "        year_links.append(player_link)\n",
    "\n",
    "        print(f'Year Link: {year_links}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_link in year_links:\n",
    "    page = requests.get(year_link)\n",
    "    year_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    strong_tag = year_soup.find('p').find('strong')\n",
    "    if strong_tag and strong_tag.text == 'League Champion':\n",
    "        champion_url = strong_tag.find_next('a')['href']\n",
    "        print(f'Champion URL:', champion_url)\n",
    "    else:\n",
    "        print('League Champion not found!')\n",
    "        \n",
    "    \n",
    "    champion_page = requests.get(champion_url, headers=headers, timeout=20)\n",
    "    if champion_page.status_code != 200:\n",
    "        print(f'Bad status code {champion_page.status_code} for {champion_url}')\n",
    "    champion_soup = BeautifulSoup(champion_page.text, 'html.parser')\n",
    "    \n",
    "    div_roster = champion_soup.find_all('div', id='div_roster')\n",
    "    trs = champion_soup.find_all('tr')[:15]\n",
    "    \n",
    "    players_ids = []\n",
    "    player_names = []\n",
    "    player_positions = []\n",
    "    player_heights = []\n",
    "    player_weights = []\n",
    "    player_experiences = []\n",
    "\n",
    "    for td in trs:\n",
    "        if td.a:\n",
    "            player_id = td.a['href'].split('/')[2].split('.')[0]\n",
    "            players_ids.append(player_id)\n",
    "            \n",
    "            # Player name\n",
    "            player_name = td.find('a').text.strip()\n",
    "            player_names.append(player_name)\n",
    "            \n",
    "            # Position\n",
    "            player_position = td.find('td', {'data-stat': 'pos'}).text.strip()\n",
    "            player_positions.append(player_position)\n",
    "            \n",
    "            # Height\n",
    "            player_height = td.find('td', {'data-stat': 'height'}).text.strip()\n",
    "            player_heights.append(player_height)\n",
    "            \n",
    "            # Weight\n",
    "            player_weight = td.find('td', {'data-stat': 'weight'}).text.strip()\n",
    "            player_weights.append(player_weight)\n",
    "            \n",
    "            # Experience\n",
    "            player_experience = td.find('td', {'data-stat': 'years_experience'}).text.strip()\n",
    "            player_experiences.append(player_experience)\n",
    "\n",
    "    print('Player IDs:', players_ids)\n",
    "    print('Player Names:', player_names)\n",
    "    print('Player Positions:', player_positions)\n",
    "    print('Player Heights:', player_heights)\n",
    "    print('Player Weights:', player_weights)\n",
    "    print('Player Experiences:', player_experiences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
